{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "TEKsRSrKeArT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 활성화 함수\n",
        "class activation_function:\n",
        "  # 시그모이드 함수\n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1+np.e**-x)\n",
        "  \n",
        "  # 시그모이드 함수의 미분 함수\n",
        "  def sigmoid_diff(self, x):  \n",
        "    return self.sigmoid(x) * (1 - self.sigmoid(x))"
      ],
      "metadata": {
        "id": "paNmDV4XiANq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용 함수 클래스, 비용 함수의 종류에 따라 다른 클래스 내 함수를 사용한다.\n",
        "class cost_function:\n",
        "  # 예측값\n",
        "  predict = []\n",
        "  # 타겟값\n",
        "  target = []\n",
        "  # 비용 함수값\n",
        "  error_cost = []\n",
        "\n",
        "  # 오차 제곱합\n",
        "  def errer_squared_sum(self, predict, target):\n",
        "    self.predict = predict\n",
        "    self.target = target\n",
        "\n",
        "    self.error_cost = np.sum(0.5*((predict - target)**2))\n",
        "    return self.error_cost\n",
        "\n",
        "  # 오차 제곱합 미분 함수\n",
        "  def diff_error_squared_sum(self, predict, target):\n",
        "    self.predict = predict\n",
        "    self.target = target\n",
        "\n",
        "    return self.predict - self.target"
      ],
      "metadata": {
        "id": "F13OlfthiwHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Rnn():\n",
        "  # 노드 입력\n",
        "  node_input = []\n",
        "\n",
        "  # 노드 출력\n",
        "  node_output = []\n",
        "  \n",
        "  def vector_to_sequence(self, input):\n",
        "    \"\"\"\n",
        "    벡터 투 시퀀스 rnn\n",
        "    벡터 입력에 대해 하나의 출력의 생성\n",
        "    \"\"\" \n",
        "    # 입력값에 사용되는 가중치\n",
        "    # (3,1) 크기의 입력 데이터에 대해 (1,1) 의 행렬곱 연산 결과를 얻기 위해, (1,3) 크기의 가중치 행렬이 필요하다\n",
        "    input_w = np.random.rand(1, input.shape[0])\n",
        "\n",
        "    # 입력 가중치의 편향값\n",
        "    input_b = np.random.rand(1)\n",
        "\n",
        "    # 이전 출력에 대한 가중치\n",
        "    # (1,1) 노드 출력에 대해 (1,1) 의 행렬곱 연산 결과를 얻기 위한, (1,1) 크기의 가중치 행렬\n",
        "    before_w = np.random.rand(1, 1)\n",
        "\n",
        "    # 이전 출력 가중치의 편향값\n",
        "    before_b = np.random.rand(1)\n",
        "\n",
        "    # 이전 노드의 출력, 첫 부분의 경우 이 값이 0이다. 행렬의 크기는 (1,1)\n",
        "    before = np.zeros((1, 1))\n",
        "\n",
        "    # (3, n) 크기의 입력 데이터에서 n 번의 반복을 수행하게 됨\n",
        "    for i in range(input.shape[1]):\n",
        "      # 노드 입력 계산\n",
        "      node_input = (before_w @ before) + (input_w @ input) + before_w\n",
        "      self.node_input.append(node_input)\n",
        "\n",
        "      # 노드 출력 계산\n",
        "      node_output = self.activation.sigmoid(node_input)\n",
        "      self.node_output.append(node_output)\n",
        "\n",
        "      before = node_output\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "09SCuL6Vticu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential 클래스\n",
        "class Sequential():\n",
        "  # 층을 차례대로 쌓아서 구성, 각 층을 배열 형태로 지정\n",
        "  layer = []\n",
        "\n",
        "  # 각 레이어 별 출력값\n",
        "  layer_result = []\n",
        "\n",
        "  # compile 정보가 저장되어 있는 딕셔너리 객체\n",
        "  compile_dir = []\n",
        "\n",
        "  # fit, 훈련 정보가 저장되어 있는 객체\n",
        "  fit_dir = []\n",
        "\n",
        "  # dense\n",
        "  dense = Dense()\n",
        "\n",
        "  # Rnn\n",
        "  rnn = Rnn()\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = cost_function()\n",
        "\n",
        "  # 활성화 함수\n",
        "  activation = activation_function()\n",
        "\n",
        "  # 비용 함수 값\n",
        "  cost_result = []\n",
        "\n",
        "  # 각 층별 가중치\n",
        "  weight_layer = []\n",
        "\n",
        "  # 각 층별 delta 값\n",
        "  delta_layer = []\n",
        "\n",
        "  # 가중치 업데이트 크기\n",
        "  weight_update_arr = []\n",
        "\n",
        "  # 각 층을 쌓기 위한 함수\n",
        "  def add(self, dict):\n",
        "    self.layer.append(dict)\n",
        "\n",
        "  # fit 함수\n",
        "  def fit(self, dict):\n",
        "    self.fit = dict\n",
        "\n",
        "    self.train(dict['data'], dict['target'])\n",
        "    \n",
        "  # compile 함수\n",
        "  def compile(self, loss = \"mse\", metrics = ['accuaray']):\n",
        "    compile_dict = dict()\n",
        "    compile_dict['loss'] = loss\n",
        "    compile_dict['metrics'] = metrics\n",
        "    \n",
        "    return compile_dict\n",
        "    \n",
        "  # train 함수\n",
        "  def train(self, data, target):\n",
        "    for i in range(len(self.layer) - 1):\n",
        "      layer_type = self.layer[i].get('layer_type')\n",
        "      if(layer_type == 'Dense'):\n",
        "        self.dense.train(self.layer[i])\n",
        "\n",
        "      if(layer_type == 'Rnn'):\n",
        "        self.rnn.train(self.layer[i])\n",
        "\n",
        "    # 비용 함수 계산, 예측값 마지막 노드의 출력\n",
        "    predict = self.dense.node_output[-1]\n",
        "\n",
        "    # 비용 함수 값의 계산\n",
        "    self.cost_result = self.cost.errer_squared_sum(predict, target)\n",
        "\n",
        "    # delta 값의 계산\n",
        "    self.cal_delta(target)\n",
        "\n",
        "  # delta 값 계산,\n",
        "  def cal_delta(self, target):\n",
        "    \n",
        "    # 초기 delta, 비용 함수의 미분값을 사용한다.\n",
        "    delta = self.cost.diff_error_squared_sum(self.dense.node_output[-1], target)\n",
        "\n",
        "    # 활성화 함수 적용 전, 노드 입력값의 변화량에 대한 비용 함수의 변화량\n",
        "    # 해당 층의 활성화 함수의 미분 함수와의 연산 수행\n",
        "    if(self.layer[-1].get('activation') == 'sigmoid'):\n",
        "      delta = delta * self.activation.sigmoid_diff(self.dense.node_input[-1])\n",
        "\n",
        "    # 해당 delta 값 저장\n",
        "    self.delta_layer.append(delta)\n",
        "\n",
        "    # 남은 레이어에 대해 delta 값 계산\n",
        "    for i in range(len(self.layer) - 1):\n",
        "      # 이전 층의 노드 출력의 변화량에 대한 비용함수의 변화량은 가중치에 해당한다.\n",
        "      delta = self.weight.T @ delta\n",
        "\n",
        "      # 해당 층의 활성화 함수의 미분 함수와의 연산 수행\n",
        "      if(self.layer[-1 -i].get('activation') == 'sigmoid'): \n",
        "        delta = delta * self.activation.sigmoid_diff(self.dense.node_input[-1 - i])\n",
        "    \n",
        "      # 해당 delta 값 저장\n",
        "      self.delta_layer.append(delta)\n",
        "\n",
        "  \n",
        "  # 가중치 업데이트량 크기 계산\n",
        "  def weight_update(self):\n",
        "    # 연산의 편리함을 위해 뒤집어준다.\n",
        "    self.delta_layer = self.delta_layer[::-1]\n",
        "\n",
        "    for i in range(len(self.weight)):\n",
        "      self.weight_update_arr.append(self.delta_layr[i] @ self.node_output[i].T)\n",
        "\n",
        "      self.weight[i] = self.weight[i] - self.weight_update_arr[i].T"
      ],
      "metadata": {
        "id": "zbRzlkNotYVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}